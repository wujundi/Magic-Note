# 流式数仓踩坑实录

## 统一NOAH的系统时间

找到 了 https://blog.csdn.net/weixin_55751581/article/details/131419643，这里面说了 spider-flow 的时区问题。按照这个思路，我需要在运行容器的时候指定时区，参考 https://blog.51cto.com/u_16175479/7649742 和 https://zhuanlan.zhihu.com/p/658390008，加上了 -e TZ=Asia/Shanghai 参数，问题解决。

---

## flink 运行环境与sql-client 环境的统一

我把hdfs下面所有的 jar 包都补充到了 flink/lib，运行之后仍然存在报错，java.lang.ClassNotFoundException: org.apache.hadoop.thirdparty.protobuf.Message，还是需要找一下这个类在 Hadoop 的什么模块下面。在源码里面一搜，有好多地方都引用了 import 了 org.apache.hadoop.thirdparty.protobuf.Message。在maven中心仓库搜索了一下，搜到的是 https://central.sonatype.com/search?q=org.apache.hadoop.thirdparty.protobuf，也在代码里面找了一下 pom 文件的版本，发现是 1.1.1，好的，那就下载吧。然后拷贝到了 /usr/bigtop/3.2.0/usr/lib/flink/lib/tmp/hadoop-shaded-protobuf_3_7-1.1.1.jar。这把OK了，在 sql-client 里面也可以创建 paimon_catalog 了。但是又两个遗留问题：

1、是在 exit 的时候会报个错误

Exception in thread "Thread-5" java.lang.IllegalStateException: Trying to access closed classloader. Please check if you store classloaders directly or indirectly in static fields. If the stacktrace suggests that the leak occurs in a third party library and cannot be fixed immediately, you can disable this check with the configuration 'classloader.check-leaked-classloader'.
        at

org.apache.flink.runtime.execution.librarycache.FlinkUserCodeClassLoaders$SafetyNetWrapperClassLoader.ensureInner(FlinkUserCodeClassLoaders.java:164)

    at org.apache.flink.runtime.execution.librarycache.FlinkUserCodeClassLoaders$SafetyNetWrapperClassLoader.getResource(FlinkUserCodeClassLoaders.java:183)
        at org.apache.hadoop.conf.Configuration.getResource(Configuration.java:2830)
        at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3104)
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3063)
        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3036)
        at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2914)
        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2896)
        at org.apache.hadoop.conf.Configuration.get(Configuration.java:1246)
        at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1863)
        at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)
        at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
        at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)
        at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)
        at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)

在往上找到了 https://blog.csdn.net/h952520296/article/details/114327232，修改了相应的配置，但是重新启动 flink 之后，配置文件就被刷掉了。然后我尝试在 ambari 页面上修改 flink 的配置文件，重启 flink 的时候，底层文件居然同步发生变动了，卧槽，ambari 是有点高效啊，连配置文件都可以在页面上修改。

其实也不用又到maven搜索又找版本的，代码里面一搜，看看 POM 里面引入的是什么东西，然后在 /usr/bigtop/3.2.0/usr/lib/hadoop/lib 这个位置都有，直接拷贝就行了。

2、catalog 的创建好像只在 session 内生效，新的 session 里面仍然需要基于hdfs 目录声明 catalog，这个有点反直觉。暂时没找到确切的说法与持久化的选项，暂时先这样吧。

---

sql-client 执行 dml 的时候会报错

Flink SQL> select * from paimon_test_table;
[ERROR] Could not execute SQL statement. Reason:
java.lang.ClassNotFoundException: com.google.protobuf.ServiceException

搜索代码之后找到maven坐标是

    `<dependency>`

    `<groupId>`com.google.protobuf `</groupId>`

    `<artifactId>`protobuf-java `</artifactId>`

    `<scope>`compile `</scope>`

    `</dependency>`

将 /usr/bigtop/3.2.0/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar 拷贝到 /usr/bigtop/3.2.0/usr/lib/flink/lib/tmp/protobuf-java-2.5.0.jar 之后，问题解决。

---

新的报错，执行 sql 的时候报错，Caused by: org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:8081

ambari 这边，flink 的后台管理页面端口是 8082 ，是不是因为这个的差异？往上找到这个 [flink 运维中遇到的问题_slot request bulk is not fulfillable! could not al_Mumunu-的博客-CSDN博客](https://blog.csdn.net/h952520296/article/details/114327232)，看起来确实是这个差异，把改成 rest.bind-port:8082 试一下，报错是不报了，但是查询也没反应，应该是端口不对。

最开始我搜索到 [Flink Connection拒绝：localhost / 127.0.0.1:8081_connect econnrefused 127.0.0.1:8081-CSDN博客](https://blog.csdn.net/u013749274/article/details/109097506) 这种帖子的时候，我是很鄙视的，你妹的，我怎么可能没启动 flink? 然后我试着先通过 start-cluster.sh 启动之后，在 sql-client 里面还真就能查询了。事实证明，我还真的就没启动 flink。

那么问题来了，streampark 运行的 flink 环境和 sql-client 运行的 flink 环境是两个独立的环境么？？？？
